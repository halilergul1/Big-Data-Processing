{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pyspark import SparkContext\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "lines = sc.textFile(\"/Users/halilergul/Desktop/master/fall-23_24/datasets-20231023/DollarDataset.txt\")\n",
    "\n",
    "def parse(line):\n",
    "    fields = line.split('\\t')\n",
    "    date = fields[1]\n",
    "    price_str = fields[2].replace('.', '').replace(',', '.') # I remove periods and replace commas with a period\n",
    "    price = 0 if price_str == '' else float(price_str) # # If the price string is empty, I assign it as 0, else float\n",
    "    return (date, price)\n",
    "data = lines.map(parse)\n",
    "\n",
    "def sort_key(item):\n",
    "    date_parts = item[0].split('-')\n",
    "    return f\"{date_parts[2]}-{date_parts[1]}-{date_parts[0]}\"\n",
    "sorted_data = data.sortBy(sort_key) # Now I sort the data by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-1, ('02-01-1950', 2.8)),\n",
       " (0, ('03-01-1950', 2.8)),\n",
       " (1, ('04-01-1950', 2.8)),\n",
       " (2, ('05-01-1950', 2.8)),\n",
       " (3, ('06-01-1950', 2.8))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifted_data = sorted_data.zipWithIndex().map(lambda x: (x[1]-1, x[0]))  # I shift index by one position to compare each day with its preceding day\n",
    "shifted_data.take(5) # zipwithindex adds an index to each element of the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 31-12-2004, the increase was 100156616.42%\n",
      "On 26-02-2001, the increase was 13.39%\n",
      "On 30-10-2008, the increase was 12.67%\n",
      "On 22-03-1991, the increase was 12.23%\n",
      "On 08-04-1994, the increase was 9.86%\n"
     ]
    }
   ],
   "source": [
    "indexed_data = sorted_data.zipWithIndex().map(lambda x: (x[1], x[0])) # I add an index to each element of the RDD\n",
    "paired_data = indexed_data.join(shifted_data).values() # This will give me pairs of (current_day, previous_day)\n",
    "\n",
    "def percentage_change(pair):\n",
    "    current_day_price = pair[0][1]\n",
    "    previous_day_price = pair[1][1]\n",
    "    if previous_day_price == 0:  # This is to avoid division by zero\n",
    "        return 0\n",
    "    return ((current_day_price - previous_day_price) / previous_day_price) * 100\n",
    "\n",
    "percentage_data = paired_data.map(lambda x: (x, percentage_change(x)))\n",
    "\n",
    "sorted_percentage_data = percentage_data.sortBy(lambda x: x[1], ascending=False) # I sort the data by percentage change in descending order\n",
    "top_5_increases = sorted_percentage_data.take(5) # I take the top 5 increases\n",
    "\n",
    "for record in top_5_increases:\n",
    "    date = record[0][0][0]\n",
    "    increase = record[1]\n",
    "    print(f\"On {date}, the increase was {increase:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
